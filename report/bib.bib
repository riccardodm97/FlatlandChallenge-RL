https://link.springer.com/content/pdf/10.1007/BF00992699.pdf



@article{experience-replay,
	author={Lin, Long-Ji},
	title={{Self-Improving Reactive Agents Based On Reinforcement Learning, Planning and Teaching}},
	journaltitle={Machine Learning},
	date={1992-05},
	volume={8},
	doi={10.1007/BF00992699},
	pages = {293–321}
}


@online{actions-rewards,
	year={2020},
	title= {{Flatland Environment}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env.html},
	urldate = {2021-07-19}
}

@online{observations,
	year={2020},
	title= {{Provided Observations}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env/observations.html},
	urldate = {2021-07-19}
}

@online{malfunctions,
	year={2020},
	title= {{Malfunctions}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env/stochasticity.html},
	urldate = {2021-07-19}
}



@online{speeds,
	year={2020},
	title= {{Speed profiles}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env/speed_profiles.html},
	urldate = {2021-07-19}
}

@online{flatland,
	year={2021},
	title= {{Flatland}},
	organization = {AIcrowd},
	url = {https://www.aicrowd.com/challenges/flatland},
	urldate = {2021-07-19}
}

@online{flatland-challenge,
	year={2020},
	title= {{Flatland Challenge}},
	organization = {AIcrowd},
	url = {https://www.aicrowd.com/challenges/flatland-challenge},
	urldate = {2021-07-19}
}

@online{multi-agent-rl,
	author={Haou, Pierre},
	year={2021},
	title= {{Multi-Agent Reinforcement Learning (MARL) and Cooperative AI}},
	organization = {Medium},
	url = {https://towardsdatascience.com/ive-been-thinking-about-multi-agent-reinforcement-learning-marl-and-you-probably-should-be-too-8f1e241606ac},
	urldate = {2021-07-19}
}

@online{understanding-ppo,
	author={Kim, Tyler},
	year={2021},
	title= {{Understanding Proximal Policy Optimization (Schulman et al., 2017)}},
	organization = {Medium},
	url = {https://towardsdatascience.com/understanding-and-implementing-proximal-policy-optimization-schulman-et-al-2017-9523078521ce},
	urldate = {2021-07-19}
}

@report{ppo-algorithm,
	author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
	title={{Proximal Policy Optimization Algorithms}},
	institution={OpenAI},
	date={2017-08-28},
	eprint={1707.06347},
	eprinttype={arxiv},
	eprintclass = {cs.LG}
}



@online{action-selectors,
	author={Juliani, Arthur},
	year={2016},
	title= {{Simple Reinforcement Learning with Tensorflow Part 7: Action-Selection Strategies for Exploration}},
	organization = {Medium},
	url = {https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-7-action-selection-strategies-for-exploration-d3a97b7cceaf},
	urldate = {2021-07-19}
}


@online{deep-reinforcement,
	author={Moghadam, Parsa Heidary},
	year={2019},
	title= {{Deep Reinforcement learning: DQN, Double DQN, Dueling DQN, Noisy DQN and DQN with Prioritized Experience Replay}},
	organization = {Medium},
	url = {https://medium.com/@parsa_h_m/deep-reinforcement-learning-dqn-double-dqn-dueling-dqn-noisy-dqn-and-dqn-with-prioritized-551f621a9823},
	urldate = {2021-07-19}
}

@online{improvements,
	author={Simonini, Thomas},
	year={2018},
	title= {{Improvements in Deep Q Learning: Dueling Double DQN, Prioritized Experience Replay, and fixed…}},
	organization = {freeCodeCamp},
	url = {https://www.freecodecamp.org/news/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682/},
	urldate = {2021-07-19}
}

@inproceedings{prioritized-experience-replay,
	author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
	title= {{Prioritized Experience Replay}},
	eventtitle={4th International Conference on Learning Representations},
	eventdate={2016-05-02/2016-05-04},
	venue={Caribe Hilton, San Juan, Puerto Rico},
	eprinttype = {arxiv},
	eprint = {1511.05952},
	eprintclass = {cs.LG}
}

@inproceedings{rainbow,
	author={Matteo Hessel and Will Dabney and Joseph Modayil and Dan Horgan and Hado van Hasselt and Bilal Piot and Tom Schaul and Mohammad Azar and Georg Ostrovski and David Silver},
	title={{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
	booktitle={Proc. 32nd AAAI Conference on Artificial Intelligence},
	eventdate={2018-02-02/2018-02-07},
	venue={New Orleans, Louisiana, USA},
	pages={3215–3222},
	url={https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/17204/16680}
}



@inbook{reinforcement-learning,
	author={Stuart J. Russell and Peter Norvig},
	title={{Reinforcement Learning}},
	booktitle={Artificial Intelligence},
	booksubtitle={{A Modern Approach}},
	publisher={Pearson Education},
	location={Upper Saddle River, NJ, USA},
	year={2009},
	edition={3},
	chapter={21},
	pages={830–859}
}

@misc{wandb,
	title = {Weights and Biases},
	year = {2021},
	organization = {Weights and Biases},
	url={https://wandb.ai/site},
	urldate = {2021-07-19}
}

