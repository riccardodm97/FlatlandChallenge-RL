
@inbook{drl-8-dqn-ddqn,
	title={{Deep Q Network (DQN), Double DQN, and Dueling DQN}},
	author={Sewak, Mohit},
	booktitle={Deep Reinforcement Learning},
	booksubtitle={Frontiers of Artificial Intelligence},
	pages={95--108},
	year={2019},
	chapter={8},
	publisher={Springer Nature Singapore},
	location ={Singapore, Singapore}
}



@online{dqn-tutorial,
	author={Wang, Mike},
	year={2020},
	title= {{Deep Q-Learning Tutorial: minDQN}},
	organization = {Medium},
	url = {https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc},
	urldate = {2021-07-19}
}


@article{experience-replay,
	author={Lin, Long-Ji},
	title={{Self-Improving Reactive Agents Based On Reinforcement Learning, Planning and Teaching}},
	journaltitle={Machine Learning},
	date={1992-05},
	volume={8},
	doi={10.1007/BF00992699},
	pages = {293--321}
}


@online{actions-rewards,
	year={2020},
	title= {{Flatland Environment}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env.html},
	urldate = {2021-07-19}
}

@online{observations,
	year={2020},
	title= {{Provided Observations}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env/observations.html},
	urldate = {2021-07-19}
}

@online{malfunctions,
	year={2020},
	title= {{Malfunctions}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env/stochasticity.html},
	urldate = {2021-07-19}
}



@online{speeds,
	year={2020},
	title= {{Speed profiles}},
	organization = {The Flatland Community},
	url = {https://flatland.aicrowd.com/getting-started/env/speed_profiles.html},
	urldate = {2021-07-19}
}



 @report{flatland,
          title={{Flatland-RL : Multi-Agent Reinforcement Learning on Trains}}, 
          author={Sharada Mohanty and Erik Nygren and Florian Laurent and Manuel Schneider and Christian Scheller and Nilabha Bhattacharya and Jeremy Watson and Adrian Egli and Christian Eichenberger and Christian Baumberger and Gereon Vienken and Irene Sturm and Guillaume Sartoretti and Giacomo Spigler},
          year={2020},
          institution={AIcrowd},
          eprint={2012.05893},
          eprinttype={arxiv},
	eprintclass = {cs.LG}
    }


@online{flatland-challenge,
	year={2020},
	title= {{Flatland Challenge}},
	organization = {AIcrowd},
	url = {https://www.aicrowd.com/challenges/flatland-challenge},
	urldate = {2021-07-19}
}

@online{multi-agent-rl,
	author={Haou, Pierre},
	year={2021},
	title= {{Multi-Agent Reinforcement Learning (MARL) and Cooperative AI}},
	organization = {Medium},
	url = {https://towardsdatascience.com/ive-been-thinking-about-multi-agent-reinforcement-learning-marl-and-you-probably-should-be-too-8f1e241606ac},
	urldate = {2021-07-19}
}

@online{understanding-ppo,
	author={Kim, Tyler},
	year={2021},
	title= {{Understanding Proximal Policy Optimization (Schulman et al., 2017)}},
	organization = {Medium},
	url = {https://towardsdatascience.com/understanding-and-implementing-proximal-policy-optimization-schulman-et-al-2017-9523078521ce},
	urldate = {2021-07-19}
}

@report{ppo-algorithm,
	author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
	title={{Proximal Policy Optimization Algorithms}},
	institution={OpenAI},
	date={2017-08-28},
	eprint={1707.06347},
	eprinttype={arxiv},
	eprintclass = {cs.LG}
}



@online{action-selectors,
	author={Juliani, Arthur},
	year={2016},
	title= {{Simple Reinforcement Learning with Tensorflow Part 7: Action-Selection Strategies for Exploration}},
	organization = {Medium},
	url = {https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-7-action-selection-strategies-for-exploration-d3a97b7cceaf},
	urldate = {2021-07-19}
}



@online{soft-update,
	year={2019},
	title= {{Learn Reinforcement Learning (3) - DQN improvement and Deep SARSA}},
	organization = {greentec.github.io},
	url = {https://greentec.github.io/reinforcement-learning-third-en/},
	urldate = {2021-07-19}
}






@online{deep-reinforcement,
	author={Moghadam, Parsa Heidary},
	year={2019},
	title= {{Deep Reinforcement learning: DQN, Double DQN, Dueling DQN, Noisy DQN and DQN with Prioritized Experience Replay}},
	organization = {Medium},
	url = {https://medium.com/@parsa_h_m/deep-reinforcement-learning-dqn-double-dqn-dueling-dqn-noisy-dqn-and-dqn-with-prioritized-551f621a9823},
	urldate = {2021-07-19}
}

@online{improvements,
	author={Simonini, Thomas},
	year={2018},
	title= {{Improvements in Deep Q Learning: Dueling Double DQN, Prioritized Experience Replay, and fixedâ€¦}},
	organization = {freeCodeCamp},
	url = {https://www.freecodecamp.org/news/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682/},
	urldate = {2021-07-19}
}

@inproceedings{prioritized-experience-replay,
	author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
	title= {{Prioritized Experience Replay}},
	eventtitle={4th International Conference on Learning Representations},
	eventdate={2016-05-02/2016-05-04},
	venue={San Juan, Puerto Rico},
	eprinttype = {arxiv},
	eprint = {1511.05952},
	eprintclass = {cs.LG}
}

@inproceedings{rainbow,
	author={Matteo Hessel and Will Dabney and Joseph Modayil and Dan Horgan and Hado van Hasselt and Bilal Piot and Tom Schaul and Mohammad Azar and Georg Ostrovski and David Silver},
	title={{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
	booktitle={Proc. 32nd AAAI Conference on Artificial Intelligence},
	eventdate={2018-02-02/2018-02-07},
	venue={New Orleans, Louisiana, USA},
	pages={3215--3222},
	url={https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/17204/16680}
}


@inproceedings{noisy,
	author={Meire Fortunato and Mohammad Gheshlaghi Azar and Bilal Piot and Jacob Menick and Matteo Hessel and Ian Osband and Alex Graves and Volodymyr Mnih and Remi Munos and Demis Hassabis and Olivier Pietquin and Charles Blundell and Shane Legg},
	title={{Noisy Networks for Exploration}},
	eventtitle={6th International Conference on Learning Representations},
	eventdate={2018-04-30/2018-05-03},
	venue={Vancouver, Canada},
	eprinttype = {arxiv},
	eprint = {1706.10295},
	eprintclass = {cs.LG}
}





@inbook{reinforcement-learning,
	author={Stuart J. Russell and Peter Norvig},
	title={{Reinforcement Learning}},
	booktitle={Artificial Intelligence},
	booksubtitle={{A Modern Approach}},
	publisher={Pearson Education},
	location={Upper Saddle River, NJ, USA},
	year={2009},
	edition={3},
	chapter={21},
	pages={830--859}
}

@misc{wandb,
	title = {{Weights and Biases}},
	year = {2021},
	organization = {Weights and Biases},
	url={https://wandb.ai/site},
	urldate = {2021-07-19}
}

